{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este notebook vamos a hacer un ejercicio de regresión usando una dataset de diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importar las siguientes librerías : numpy (como np), pandas (como pd) y matplotlib.pylab ( como plt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leer el archivo de datos \"diabetes\" usando pandas, llámandolo \"diabetes_df\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_excel('../../datasets/diabetes.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a recordar un poco las herramientas aprendidas el otro día."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usa un método de pandas para mostrar información sobre el tipo de variable y el numero de no nulos de la data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usa un método de pandas para mostrar información estadística que resuma la información estadística de cada variable de los datos**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mediante un loop, muestra el valor medio de cada variable (columna). Para ello, tendréis que utilizar alguno de los métodos de pandas para seleccionar columnas y después aplicar la función, que se encuentra en la librería numpy. Comprobar que coincide con el valor que muestra en la celda anterior. (Puede ser también útil acceder a los nombres de las columnas, mediante el uso del método `columns` que tienen los dataframes de pandas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diabetes_df.columns:\n",
    "    print( \"la media de la variable \", col, \" es igual a= \", np.mean(diabetes_df.loc[:,col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mediante un loop y usando la librería matplotlib, plotear cada las primeras diez variables con respecto la última, llamada progression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in diabetes_df.columns[0:10]:\n",
    "    plt.figure()\n",
    "    a = diabetes_df.loc[:, col].values\n",
    "    b = diabetes_df.loc[:, 'progression'].values\n",
    "    plt.scatter(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crear un dataframe con el 70% de las primeras observaciones y otro con el 30% restante. Llamad al primero \"train_df\" y al segundo \"test_df\". (Ayuda= Igual necesitáis convertir el número que de observaciones que vais a coger a entero. Para ello, usad la function `int`, nativa de python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= diabetes_df.iloc[:int(diabetes_df.shape[0]*0.7),:]\n",
    "test_df= diabetes_df.iloc[int(diabetes_df.shape[0]*0.7):,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A su vez, coged las primeras diez columnas y cread para ambas datasets un array de numpy con los nombres \"X_train\" y \"X_test\". Asimismo, cread otro array de numpy para las dos datasets con unicamente la columna \"progresión\". Llamad a estos objetos \"y_train\" e \"y_test\" respectivamete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.drop(columns=[\"progression\"]).values\n",
    "X_test=test_df.drop(columns=[\"progression\"]).values\n",
    "y_train= train_df['progression'].values\n",
    "y_test= test_df['progression'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regresión univariada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primero, cargad los métodos de regresión linear_regression, lasso, Ridge y ElasticNet de scikit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargad a su vez el módulo de scikit `metrics`, que lo usaremos para medir el rendimiento de los métodos de regresión recién importados **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encontrad el rendimiento de cada variable de manera individual para predecir la variable progression. Para ello, ajustad el modelo usando X_train e y_train, para posteriormente, predecir en los datos X_test. Comparad el resultado predicho con el real y_test mediante el uso de las métricas aprendidas. Haced esto para esto solo para la regresión lineal sin regularización, i.e., la función que acabamos de cargar `LinearRegression()` (Ayuda: acordáos de que X tiene que ser siempre una matriz, aunque sólo tengamos una variable. Quizá en algún momento debéis usar la función `reshape` de numpy)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression()\n",
    "for idx in range(X_train.shape[1]):\n",
    "    # Hacemos fit\n",
    "\n",
    "    clf.fit(X_train[:,idx].reshape(-1,1), y_train)\n",
    "    # Hacemos predict\n",
    "    Y_pred = clf.predict(X_test[:,idx].reshape(-1,1))\n",
    "    \n",
    "    evs = metrics.explained_variance_score(y_test, Y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_test, Y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, Y_pred)\n",
    "    mne=  metrics.median_absolute_error(y_test, Y_pred)\n",
    "    r2= metrics.r2_score(y_test, Y_pred)\n",
    "    \n",
    "    #print(\" las metricas para el modelo \", clas_names[idx], \" son \")\n",
    "    print(\"evs = \" , np.round(evs, 3), \" mae= \", np.round(mae,3), \" mse= \",np.round(mse,3),\\\n",
    "          \" mne = \", np.round(mne,3), \" r2 = \", np.round(r2, 3))\n",
    "    print(\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Haced para cada variable un scatter plot ploteando los valores predichos frente a los reales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(X_train.shape[1]):\n",
    "    # Hacemos fit\n",
    "\n",
    "    clf.fit(X_train[:,idx].reshape(-1,1), y_train)\n",
    "    # Hacemos predict\n",
    "    y_pred = clf.predict(X_test[:,idx].reshape(-1,1))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usad la función `corrcoef` para cuantificar la similaridad entre la predicción y los valores reales. Si tennéi alguna duda de cómo usar dicha función, abrid el menú de ayuda usando `help` o `??`, o entrad en []().**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(X_train.shape[1]):\n",
    "    # Hacemos fit\n",
    "\n",
    "    clf.fit(X_train[:,idx].reshape(-1,1), y_train)\n",
    "    # Hacemos predict\n",
    "    y_pred = clf.predict(X_test[:,idx].reshape(-1,1))\n",
    "    \n",
    "    print(\"pearson coeficient =\", np.corrcoef(y_test,y_pred)[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usando todas las variables, comparar el rendimiento entre los cuatro algoritmos cargados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1, clf_2, clf_3, clf_4 = LinearRegression(normalize=False), Lasso(normalize=False), Ridge(normalize=False),ElasticNet(normalize=False)\n",
    "\n",
    "for clf in [clf_1,clf_2,clf_3, clf_4]:\n",
    "    # Hacemos fit\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Hacemos predict\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    \n",
    "    evs = metrics.explained_variance_score(y_test, Y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_test, Y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, Y_pred)\n",
    "    mne=  metrics.median_absolute_error(y_test, Y_pred)\n",
    "    r2= metrics.r2_score(y_test, Y_pred)\n",
    "    \n",
    "    #print(\" las metricas para el modelo \", clas_names[idx], \" son \")\n",
    "    print(\"evs = \" , np.round(evs, 3), \" mae= \", np.round(mae,3), \" mse= \",np.round(mse,3),\\\n",
    "          \" mne = \", np.round(mne,3), \" r2 = \", np.round(r2, 3))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1.fit(X_train, y_train)\n",
    "Y_pred = clf_1.predict(X_test)\n",
    "print(metrics.explained_variance_score(y_test, Y_pred))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss= StandardScaler()\n",
    "clf_1.fit(ss.fit_transform(X_train), y_train)\n",
    "Y_pred = clf_1.predict(ss.transform(X_test))\n",
    "print(metrics.explained_variance_score(y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
