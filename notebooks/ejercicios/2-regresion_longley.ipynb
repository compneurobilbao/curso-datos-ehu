{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este notebook vamos a hacer un ejercicio de regresión usando una dataset de longley, que se sabe que la data es muy colineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importar las siguientes librerías : numpy (como np), pandas (como pd) y matplotlib.pylab ( como plt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leer el archivo de datos `longley` usando pandas, llámandolo \"longley_df\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longley_df = pd.read_excel('../../datasets/longley.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vamos a recordar un poco las herramientas aprendidas el otro día."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usa un método de pandas para mostrar información sobre el tipo de variable y el numero de no nulos de la data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longley_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usa un método de pandas para mostrar información estadística que resuma la información estadística de cada variable de los datos**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longley_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mediante un loop, muestra el valor medio de cada variable (columna). Para ello, tendréis que utilizar alguno de los métodos de pandas para seleccionar columnas y después aplicar la función, que se encuentra en la librería numpy. Comprobar que coincide con el valor que muestra en la celda anterior. (Puede ser también útil acceder a los nombres de las columnas, mediante el uso del método `columns` que tienen los dataframes de pandas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in longley_df.columns:\n",
    "    print( \"la media de la variable \", col, \" es igual a= \", np.mean(longley_df.loc[:,col]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mediante un loop y usando la librería matplotlib, plotear cada las primeras diez variables con respecto la última, llamada Employed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in longley_df.columns[0:6]:\n",
    "    plt.figure()\n",
    "    a = longley_df.loc[:, col].values\n",
    "    b = longley_df.loc[:, 'Employed'].values\n",
    "    plt.scatter(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión  de la variable *GNP.deflector*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crear un dataframe con el 70% de las primeras observaciones y otro con el 30% restante. Llamad al primero \"train_df\" y al segundo \"test_df\". (Ayuda= Igual necesitáis convertir el número que de observaciones que vais a coger a entero. Para ello, usad la function `int`, nativa de python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = longley_df.iloc[:int(0.7*longley_df.shape[0]),:]\n",
    "test_df = longley_df.iloc[int(0.7*longley_df.shape[0]):,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A su vez, coged las primeras diez columnas y cread para ambas datasets un array de numpy con los nombres \"X_train\" y \"X_test\". Asimismo, cread otro array de numpy para las dos datasets con unicamente la columna \"GNP.deflector\". Llamad a estos objetos \"y_train\" e \"y_test\" respectivamete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.drop(columns=[\"GNP.deflator\"]).values\n",
    "X_test=test_df.drop(columns=[\"GNP.deflator\"]).values\n",
    "y_train= train_df['GNP.deflator'].values\n",
    "y_test= test_df['GNP.deflator'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cargad el métodos de regresión linear_regression de scikit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargad a su vez el módulo de scikit `metrics`, que lo usaremos para medir el rendimiento de los métodos de regresión recién importados **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reportar el error medio cuadrado del ajuste para X e y usando el método de regresión lineal anteriormente cargado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LinearRegression(normalize=True)\n",
    "clf.fit(X_train,y_train)\n",
    "print(metrics.mean_squared_error(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LinearRegression(normalize=False)\n",
    "clf.fit(X_train,y_train)\n",
    "print(metrics.mean_squared_error(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "clf=LinearRegression(normalize=False)\n",
    "clf.fit(ss.fit_transform(X_train),y_train)\n",
    "print(metrics.mean_squared_error(y_test,clf.predict(ss.transform(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Reportar el error medio cuadrado del ajuste para X e y usando como método de regresión `Ridge`. Reportad a su vez eso para diferentes valores entre 0.001 y 1000 del coeficiente de regularización ( *alpha* en la función `Ridge` de scikit). Podéis hacer un plot de dicha variación, por ejemplo **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas=10.0**np.arange(-3,3,0.5)\n",
    "list_metrics=[]\n",
    "for alpha in alphas:\n",
    "    clf=Ridge(alpha=alpha)\n",
    "    clf.fit(X_train,y_train)\n",
    "    list_metrics.append(metrics.mean_squared_error(y_test,clf.predict(X_test)))\n",
    "\n",
    "plt.plot(list_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alphas=10.0**np.arange(-3,3,0.5)\n",
    "list_metrics=[]\n",
    "for alpha in alphas:\n",
    "    clf=Lasso(alpha=alpha)\n",
    "    clf.fit(X_train,y_train)\n",
    "    list_metrics.append(metrics.mean_squared_error(y_test,clf.predict(X_test)))\n",
    "\n",
    "plt.plot(list_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Repetid el ajuste usando el modelo lineal simple pero ahora quitando las columnas *GNP*, *Population* y *Year*. ¿Mejora o disminuye la predicción? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_df.drop(columns=[\"GNP\", \"Population\",\"Year\",\"GNP.deflator\"]).values\n",
    "X_test=test_df.drop(columns=[\"GNP\", \"Population\",\"Year\",\"GNP.deflator\"]).values\n",
    "y_train= train_df['GNP.deflator'].values\n",
    "y_test= test_df['GNP.deflator'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LinearRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "print(metrics.mean_squared_error(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longley_df.drop(columns=[\"GNP.deflator\"]).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(longley_df.drop(columns=[\"GNP.deflator\"]).corr())\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
