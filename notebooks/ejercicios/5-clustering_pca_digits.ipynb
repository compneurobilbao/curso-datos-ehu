{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cargad las tres librerías de siempre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scikit tiene una dataset de digitos, dentro del módulo datasets. Importad la clase necesaria para poder cargar la dataset y definid un objeto llamado `data_digits` a partir de ella. Entrad en la documentación de scikit para poder encontrar la clase necesaria http://scikit-learn.org/stable/datasets/index.html#datasets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "data_digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Cread una matriz de features X y un array y con el target. Cuando cargáis los datos usando la clase del apartado anterior, lo que estáis creando es un diccionario, donde una entrada es `data`, que contiene las features, y otra entrada llamada `target`, a partir de la cual podréis crear el array y de targets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_digits['data']\n",
    "y = data_digits['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_digits.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Otro de los elementos de la dataset cargada, es una entrada con el nombre `images`, que contine las imágenes 8x8 de los digitos en escala de grises. De hecho, los features no son más que estos 8x8 pixels.Las imagenes corresponden a representanciones diferentes de 10 dígitos, desde el 0 al 9. Usando matplotlib, plotead 10 imagenes de cada dígito. Podéis usar la función `imshow` pasándole las imágenes y una paleta plt.cm.gray_r, pasando esto al argumento `cmap` de la función `imshow` . Si tenéis alguna duda sobre cómo usar dicha función, podéis mirar en https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html . Ayuda: basta con que ploteéis las diez primeras imágenes **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_digits.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=10, nrows=1)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    axs[i].imshow(data_digits['images'][i,:,:], cmap=plt.cm.gray_r)\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vamos a hacer una pca sobre estos datos. Como los datos tienen que estar estandarizados, importad la clase que hace esto en scikit y transformad los datos **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_scaled = ss.fit_transform(X) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Importad la clase de PCA **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Definid una variable del objeto  PCA, que explique al menos el 75 % de variación de los datos **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca= PCA(n_components=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usad este objeto recién creado para ajustarlo a  los datos estandarizados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mostrad el número de componentes principales seleccionadas por la pca**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mostrad en un plot usando la función `plot` de matplotlib cómo la variación explicada va aumentando hasta llegar a la cantidad requerida cuando hemos definido la pca. Para ello, después de fittear la pca, tenéis que acceder a su atributo *explained_variance_ratio__* (con una sola barra baja al final) y usar sobre esto la función `cumsum` de numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,pca.n_components_+1),np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xticks(np.arange(1,pca.n_components_+1))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Transformad los datos al espacio de las componentes principales. Para ello, una vez fitteada la pca, tenéis que usar el método `transform` sobre los datos estandarizados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Mostrad el tamaño de los datos transformados y ved que en efecto, el número de features ahora se ha reducido al número de componentes seleccionadas por la pca ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Los datos transformados, devolvedlos al espacio original. Para ello, vais a tener que llamar al método `inverse_transform` tanto de la pca primero, como del objeto que estandarizaba los datos después **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rec = pca.inverse_transform(X_pca)\n",
    "X_rec = ss.inverse_transform(X_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Una vez hecho esto, volved a plotear las imágenes de los dígitos que habéis ploteado antes, pero ahora usando los datos reconstruidos que hemos obtenido en el apartado anterior **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=10, nrows=1)\n",
    "axs = axs.flatten()\n",
    "for i in range(10):\n",
    "    \n",
    "    axs[i].imshow(X_rec[i,:].reshape(8,8), cmap=plt.cm.gray_r)\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Extra: Intentad lo mismo usando la dataset de olivetti faces, que la podéis decargar usando la clase `fetch_olivetti_faces` en el módulo datasets de scikit. De esta manera, podréis ver cómo cambian las caras originales respecto a las reconstruidas por la pca **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "data_faces= fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedimos el 95% de la variación explicada\n",
    "pca= PCA(n_components=0.95,random_state=0) \n",
    "pca.fit(data_faces['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_tr =  pca.fit_transform(data_faces['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_inv = pca.inverse_transform(faces_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una cara de los datos originales\n",
    "plt.imshow(data_faces['data'][0,:].reshape(64,64), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La misma cara de los datos reconstruidos por la pca\n",
    "plt.imshow(faces_inv[0,:].reshape(64,64), cmap=plt.cm.gray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
