{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En este notebook vamos a aplicar algunas herrammientas aprendidas para hacer clasificación. Para ello utilizaremos la Mammographic Dataset, que se encuentra en http://archive.ics.uci.edu/ml/index.php\n",
    "\n",
    "1. Title: Mammographic Mass Data\n",
    "\n",
    "2. Sources:\n",
    "\n",
    "   (a) Original owners of database:\n",
    "        Prof. Dr. R�diger Schulz-Wendtland\n",
    "        Institute of Radiology, Gynaecological Radiology, University Erlangen-Nuremberg\n",
    "        Universit�tsstra�e 21-23\n",
    "        91054 Erlangen, Germany\n",
    "        \n",
    "   (b) Donor of database:\n",
    "        Matthias Elter\n",
    "        Fraunhofer Institute for Integrated Circuits (IIS)\n",
    "        Image Processing and Medical Engineering Department (BMT) \n",
    "        Am Wolfsmantel 33\n",
    "        91058 Erlangen, Germany\n",
    "        matthias.elter@iis.fraunhofer.de\n",
    "        (49) 9131-7767327 \n",
    "        \n",
    "   (c) Date received: October 2007\n",
    " \n",
    "3. Past Usage:\n",
    "    M. Elter, R. Schulz-Wendtland and T. Wittenberg (2007)\n",
    "    The prediction of breast cancer biopsy outcomes using two CAD approaches that both emphasize an intelligible decision process.\n",
    "    Medical Physics 34(11), pp. 4164-4172\n",
    "\n",
    "4. Relevant Information:\n",
    "    Mammography is the most effective method for breast cancer screening\n",
    "    available today. However, the low positive predictive value of breast\n",
    "    biopsy resulting from mammogram interpretation leads to approximately\n",
    "    70% unnecessary biopsies with benign outcomes. To reduce the high\n",
    "    number of unnecessary breast biopsies, several computer-aided diagnosis\n",
    "    (CAD) systems have been proposed in the last years.These systems\n",
    "    help physicians in their decision to perform a breast biopsy on a suspicious\n",
    "    lesion seen in a mammogram or to perform a short term follow-up\n",
    "    examination instead.\n",
    "    This data set can be used to predict the severity (benign or malignant)\n",
    "    of a mammographic mass lesion from BI-RADS attributes and the patient's age.\n",
    "    It contains a BI-RADS assessment, the patient's age and three BI-RADS attributes\n",
    "    together with the ground truth (the severity field) for 516 benign and\n",
    "    445 malignant masses that have been identified on full field digital mammograms\n",
    "    collected at the Institute of Radiology of the\n",
    "    University Erlangen-Nuremberg between 2003 and 2006.\n",
    "    Each instance has an associated BI-RADS assessment ranging from 1 (definitely benign)\n",
    "    to 5 (highly suggestive of malignancy) assigned in a double-review process by\n",
    "    physicians. Assuming that all cases with BI-RADS assessments greater or equal\n",
    "    a given value (varying from 1 to 5), are malignant and the other cases benign,\n",
    "    sensitivities and associated specificities can be calculated. These can be an\n",
    "    indication of how well a CAD system performs compared to the radiologists.\n",
    "\n",
    "5. Number of Instances: 961\n",
    "\n",
    "6. Number of Attributes: 6 (1 goal field, 1 non-predictive, 4 predictive attributes)\n",
    "\n",
    "7. Attribute Information:\n",
    "   1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "   2. Age: patient's age in years (integer)\n",
    "   3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "   4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "   5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "   6. Severity: benign=0 or malignant=1 (binominal)\n",
    "\n",
    "8. Missing Attribute Values: Yes\n",
    "    - BI-RADS assessment:    2\n",
    "    - Age:                   5\n",
    "    - Shape:                31\n",
    "    - Margin:               48\n",
    "    - Density:              76\n",
    "    - Severity:              0\n",
    "\n",
    "9. Class Distribution: benign: 516; malignant: 445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_data=pd.read_csv('../../datasets/mammographic_masses.data', na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_data.columns=['bi_rads', 'age','shape','margin','density','severity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs=plt.subplots(ncols=2, nrows=3)\n",
    "axs=axs.flatten()\n",
    "for i,ax in enumerate(axs):\n",
    "    ax.hist(mam_data.dropna()[mam_data.dropna().iloc[:,5]==0].iloc[:,i])\n",
    "    ax.hist(mam_data.dropna()[mam_data.dropna().iloc[:,5]==1].iloc[:,i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotear categorical y ordinal data usando seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "for var in ['bi_rads','shape','margin','density']:\n",
    "    plt.figure()\n",
    "    sns.countplot(x=var, hue='severity', data=mam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='severity', y='age', data=mam_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mam_data_clean = mam_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mam_data_clean.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos como siempre una matriz de features y un vector de targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=mam_data_clean.drop(columns=['severity']).values\n",
    "y=mam_data_clean['severity'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos los datos en train y test usando la funcion `train_test_split de scikit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a probar un árbol de decisión y random forest, que no requieren mucho preprocessing de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"la accuracy del arbol de decision es: \", clf.score(X_test, y_test))\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"la accuracy del random forest es: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in np.arange(1,10):\n",
    "    clf=DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    plt.plot(depth, clf.score(X_test, y_test), '.r')    \n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qué pasa si hacemos lo mismo con Support Vector Machines, por ejemplo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf=SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"la accuracy de SVM es: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno tiene que convertir los datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oHe=OneHotEncoder(categorical_features=[0,2,3,4], sparse=False)\n",
    "X_train_transform = oHe.fit_transform(X_train)\n",
    "X_test_transform = oHe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, conviene tener todas las variables con la misma escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_transform =  ss.fit_transform(X_train_transform)\n",
    "X_test_transform =  ss.transform(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_transform.mean(axis=0), X_train_transform.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_transform, y_train)\n",
    "print(\"la accuracy de SVM es: \", clf.score(X_test_transform, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver cómo varía la clasificación cambiado los parámetros del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in 10**np.arange(-2,2, 0.2):\n",
    "    clf=SVC(C=C)\n",
    "    clf.fit(X_train_transform, y_train)\n",
    "    plt.plot(C, clf.score(X_test_transform, y_test), '.r') # Mejor en escala logarítmica\n",
    "    #plt.semilogx(C, clf.score(X_test_transform, y_test), '.r')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "for neigh in np.arange(1,20, 1):\n",
    "    clf=KNeighborsClassifier(n_neighbors=neigh)\n",
    "    clf.fit(X_train_transform, y_train)\n",
    "    plt.plot(neigh, clf.score(X_test_transform, y_test), '.r')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(max_depth=3, n_estimators=100)\n",
    "clf.fit(X_train_transform, y_train)\n",
    "clf.score(X_test_transform, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sub = X_train[:,[0,1,2,3,4]]\n",
    "X_test_sub = X_test[:,[0,1,2,3,4]] \n",
    "\n",
    "oHe=OneHotEncoder(categorical_features=[0,2,3,4], sparse=False)\n",
    "X_train_transform = oHe.fit_transform(X_train_sub)\n",
    "X_test_transform = oHe.transform(X_test_sub)\n",
    "\n",
    "X_train_transform =  ss.fit_transform(X_train_transform)\n",
    "X_test_transform =  ss.transform(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=SVC()\n",
    "clf.fit(X_train_transform, y_train)\n",
    "print(\" la accuray después de eliminar features es: \", clf.score(X_test_transform, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con los NaNs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mam_data['severity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_1 = Imputer(strategy='mean')\n",
    "temp_1 = imp_1.fit_transform(mam_data['age'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_2 = Imputer(strategy='most_frequent')\n",
    "temp_2 = imp_2.fit_transform(mam_data.loc[:,['bi_rads','shape','margin','density']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.concatenate((temp_1,temp_2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oHe=OneHotEncoder(categorical_features=[1,2,3,4], sparse=False)\n",
    "X_train_transform = oHe.fit_transform(X_train)\n",
    "X_test_transform = oHe.transform(X_test)\n",
    "ss = StandardScaler()\n",
    "X_train_transform =  ss.fit_transform(X_train_transform)\n",
    "X_test_transform =  ss.fit_transform(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_train_transform[:,20])\n",
    "plt.xlabel(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in 10**np.arange(-2,2, 0.2):\n",
    "    clf=SVC(C=C)\n",
    "    clf.fit(X_train_transform, y_train)\n",
    "    plt.plot(C, clf.score(X_test_transform, y_test), '.r') # Mejor en escala logarítmica\n",
    "    plt.semilogx(C, clf.score(X_test_transform, y_test), '.r')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('C')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
